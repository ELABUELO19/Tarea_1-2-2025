# Tarea Sistemas distribuidos 1

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)

Sistema acad√©mico para an√°lisis comparativo de pol√≠ticas de cache con **modelos LLM simulados** (Dummy-LLM), dise√±ado para testing y desarrollo sin dependencias externas de APIs.

## Caracter√≠sticas Principales

- **Dummy-LLM**: Simulaci√≥n realista de 3 modelos (GPT-4o, GPT-4o-mini, Mistral-Nemo)
- ** Cache Inteligente**: 15 configuraciones diferentes (LRU, TTL, TTL-LRU)
- ** An√°lisis Completo**: M√©tricas detalladas de rendimiento y calidad
- ** Docker Ready**: Despliegue completo con un solo comando
- ** Visualizaci√≥n**: Gr√°ficos autom√°ticos y reportes detallados

## Componentes del Sistema

### Servicios Docker

| Servicio | Funci√≥n | Puerto | Descripci√≥n |
|----------|---------|--------|-------------|
| **PostgreSQL** | Base de datos principal | 5432 | Almacena dataset y resultados |
| **Redis** | Sistema de cache | 6379 | Implementa pol√≠ticas de cache |
| **Load_data** | Cargar dataset | - | Cargar preguntas en la base de datos y respuestas |
| **Analyzer** | Motor de an√°lisis | - | Ejecuta experimentos y genera reportes |

### Componentes Python

- **`dummy_llm_service.py`**: Simulador de modelos LLM sin APIs externas
- **`analyzer.py`**: Motor principal de an√°lisis y experimentaci√≥n
- **`cache_manager.py`**: Gestor de pol√≠ticas de cache Redis
- **`database.py`**: Gestor de conexi√≥n y esquema PostgreSQL
- **`load_data.py`**: Cargador del dataset Yahoo Answers

## Inicio R√°pido

### M√©todo Recomendado: Docker (Un Solo Comando)

```bash
# Despliegue completo autom√°tico
docker-compose up --build

# An√°lisis con volumen personalizado
docker-compose run --rm analyzer python analyzer.py --requests 1000
```

**¬øQu√© incluye el an√°lisis autom√°tico?**
- PostgreSQL + Redis (servicios base)
- Carga autom√°tica de 5,000 registros
- Simulaci√≥n LLM con 3 modelos
- 15 configuraciones de cache
- Reportes y gr√°ficos autom√°ticos
- Tiempo estimado: 15-30 minutos

### Configuraciones Personalizadas

```bash
# An√°lisis r√°pido (1,000 solicitudes)
docker-compose run --rm analyzer python analyzer.py --requests 1000

# Solo an√°lisis de cache (sin Dummy-LLM)
docker-compose run --rm analyzer python analyzer.py --cache-only

# Modo test r√°pido (100 solicitudes)
docker-compose run --rm analyzer python analyzer.py --test
```

## Sistema Dummy-LLM

### Modelos Simulados

| Modelo | Caracter√≠sticas | Tiempo Simulado | Calidad Base |
|--------|----------------|-----------------|--------------|
| **GPT-4o** | Respuestas detalladas y precisas | 2-4 segundos | Alta (8.5-9.5) |
| **GPT-4o-mini** | Respuestas r√°pidas y eficientes | 1-2 segundos | Media (7.0-8.5) |
| **Mistral-Nemo** | Balance entre calidad y velocidad | 1.5-3 segundos | Media-Alta (7.5-9.0) |

### Generaci√≥n de Respuestas

El Dummy-LLM genera respuestas realistas basadas en:
- **An√°lisis de contenido**: Extrae palabras clave de la pregunta
- **Categorizaci√≥n autom√°tica**: Clasifica por tipo de pregunta
- **Templates din√°micos**: Utiliza plantillas seg√∫n la categor√≠a
- **Scoring determinista**: Asigna puntuaciones basadas en complejidad
- **Variaci√≥n simulada**: Introduce variabilidad realista en tiempos

## Pol√≠ticas de Cache Analizadas

### LRU (Least Recently Used)
- **Descripci√≥n**: Elimina elementos menos recientemente utilizados
- **Ventajas**: Excelente para patrones de acceso temporal
- **Casos de uso**: Sistemas con localidad temporal fuerte
- **Tama√±os**: 10, 100, 500, 1,000, 2,000 entradas

### TTL (Time To Live)
- **Descripci√≥n**: Elimina elementos despu√©s de un tiempo fijo
- **Ventajas**: Control preciso del tiempo de vida
- **Casos de uso**: Datos con validez temporal conocida
- **Configuraciones**: 30s, 60s, 300s, 600s, 1800s

### TTL-LRU (H√≠brido)
- **Descripci√≥n**: Combina expiraci√≥n temporal con pol√≠tica LRU
- **Ventajas**: Optimiza tanto tiempo como frecuencia de acceso
- **Casos de uso**: Aplicaciones de alta demanda con datos mixtos
- **Total**: 15 configuraciones diferentes

## M√©tricas Analizadas

### Rendimiento de Cache
- **Hit Rate**: Porcentaje de aciertos en cache (0-100%)
- **Miss Rate**: Porcentaje de fallos en cache (0-100%)
- **Latency**: Tiempo de respuesta promedio (ms)
- **Memory Usage**: Utilizaci√≥n de memoria del cache
- **Eviction Rate**: Tasa de eliminaci√≥n de elementos

### Calidad Dummy-LLM
- **Response Quality**: Puntuaci√≥n de calidad (1-10)
- **Response Time**: Tiempo de generaci√≥n simulado
- **Model Comparison**: Ranking comparativo entre modelos
- **Consistency**: Variabilidad en respuestas del mismo modelo

### M√©tricas del Sistema
- **Throughput**: Solicitudes procesadas por segundo
- **Resource Utilization**: CPU, memoria, red
- **Error Rate**: Tasa de errores y timeouts
- **Scalability**: Comportamiento con diferentes vol√∫menes

## Resultados y Reportes

### Archivos Generados

```
results/
‚îú‚îÄ‚îÄ cache_analysis_report.txt      # Reporte textual detallado
‚îú‚îÄ‚îÄ cache_analysis_charts.png      # Dashboard gr√°fico completo
‚îú‚îÄ‚îÄ hit_rate_comparison.png        # Comparaci√≥n de hit rates
```

### Interpretaci√≥n de Resultados

- **Hit Rate > 70%**: Excelente configuraci√≥n de cache
- **Quality Score > 8.0**: Alta calidad en respuestas Dummy-LLM
- **Latency < 100ms**: Rendimiento √≥ptimo
- **Memory Usage < 80%**: Utilizaci√≥n eficiente

## Arquitectura del Sistema

```mermaid
graph TB
    A[Client Request] --> B[Analyzer]
    B --> C[Cache Manager]
    B --> D[Dummy-LLM Service]
    C --> E[Redis Cache]
    D --> F[GPT-4o Simulator]
    D --> G[GPT-4o-mini Simulator]
    D --> H[Mistral-Nemo Simulator]
    B --> I[PostgreSQL]
    I --> J[Results & Reports]
```

### Flujo de Ejecuci√≥n

1. **Inicializaci√≥n**: PostgreSQL + Redis + Dummy-LLM
2. **Carga de datos**: 5,000 preguntas del dataset Yahoo Answers
3. **An√°lisis Dummy-LLM**: Simulaci√≥n de procesamiento con 3 modelos
4. **An√°lisis Cache**: 15 configuraciones secuenciales con datos simulados
5. **Generaci√≥n**: Reportes y gr√°ficos comparativos
6. **Finalizaci√≥n**: Resultados disponibles en `/results`

## üõ†Ô∏è Desarrollo Local

### Instalaci√≥n Manual

```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar base de datos
python database.py
python load_data.py

# Ejecutar an√°lisis
python analyzer.py --requests 1000
```

### Dependencias

```python
# requirements.txt (sin APIs externas)
psycopg2-binary>=2.9.0
redis>=5.0.0
sqlalchemy>=2.0.0
pandas>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
python-dotenv>=1.0.0
```

## Troubleshooting

### Errores Comunes

**Error: "Container failed to start"**
```bash
# Soluci√≥n: Verificar Docker y reconstruir
docker-compose down
docker-compose up --build
```

**Error: "Database connection failed"**
```bash
# Soluci√≥n: Esperar a que PostgreSQL est√© listo
docker-compose logs postgres
```

**Error: "Cache analysis incomplete"**
```bash
# Soluci√≥n: Verificar logs del analizador
docker-compose logs analyzer
```

### Debug Mode

```bash
# Activar logging detallado
export LOG_LEVEL=DEBUG
docker-compose run --rm analyzer python analyzer.py --debug
```
