#!/usr/bin/env python3
"""
Script para cargar datos CSV en la base de datos PostgreSQL dockerizada
"""

import pandas as pd
import psycopg2
from sqlalchemy import create_engine
import sys
import os

def main():
    print("=== CARGANDO DATOS EN BASE DE DATOS DOCKERIZADA ===")
    
    # ConfiguraciÃ³n de base de datos
    DATABASE_CONFIG = {
        'host': 'localhost',
        'port': 5432,
        'database': 'yahoo_answers',
        'user': 'postgres',
        'password': 'postgres123'
    }
    
    # Archivo CSV
    csv_file = 'train.csv'
    
    if not os.path.exists(csv_file):
        print(f"âŒ Error: No se encuentra el archivo {csv_file}")
        return
    
    try:
        print(f"ğŸ“‚ Leyendo archivo CSV: {csv_file}")
        # El CSV no tiene headers, definimos los nombres de columnas
        column_names = ['original_class', 'question_title', 'question_content', 'original_answer']
        df = pd.read_csv(csv_file, names=column_names, header=None)
        print(f"âœ… Archivo leÃ­do: {len(df)} registros")
        
        # Mostrar informaciÃ³n del dataset
        print(f"ğŸ“‹ Columnas: {list(df.columns)}")
        print(f"ğŸ“‹ Ejemplo de datos:")
        print(df.head(2).to_string())
        
        # Crear conexiÃ³n
        connection_string = f"postgresql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}"
        engine = create_engine(connection_string)
        
        print("ğŸ”Œ Conectando a PostgreSQL...")
        
        # Limpiar datos nulos
        df = df.fillna('')
        
        # Limitar a un subconjunto para testing (puedes cambiar este nÃºmero)
        # Para pruebas iniciales, usemos solo 10,000 registros
        if len(df) > 10000:
            print(f"ğŸ”„ Limitando a 10,000 registros para prueba inicial (total disponible: {len(df)})")
            df = df.head(10000)
        
        print(f"ğŸ’¾ Insertando {len(df)} registros en la base de datos...")
        
        # Insertar en lotes para mejor rendimiento
        batch_size = 1000
        total_inserted = 0
        
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            batch.to_sql('questions', engine, if_exists='append', index=False, method='multi')
            total_inserted += len(batch)
            print(f"ğŸ“ˆ Progreso: {total_inserted}/{len(df)} registros insertados")
        
        print(f"âœ… Â¡Datos cargados exitosamente! Total: {total_inserted} registros")
        
        # Verificar inserciÃ³n
        with engine.connect() as conn:
            result = conn.execute("SELECT COUNT(*) FROM questions")
            count = result.fetchone()[0]
            print(f"ğŸ” VerificaciÃ³n: {count} registros en la tabla questions")
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        return
    
    print("âœ… Â¡Proceso completado!")

if __name__ == "__main__":
    main()
